# -*- coding: utf-8 -*-
"""sentiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Eh4jukWVWM64wJYWurXHLgk1idIFgizm
"""

!pip install transformers
!pip install torch

!pip install datasets
!pip install tensorboard

!pip install flask

from transformers import DistilBertTokenizer, DistilBertForSequenceClassification
from datasets import load_dataset
from transformers import Trainer, TrainingArguments
import torch

dataset = load_dataset('imdb')
train_dataset = dataset['train']
test_dataset = dataset['test']

tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

def tokenize_function(examples):
    return tokenizer(examples['text'], padding="max_length", truncation=True)

tokenized_train = train_dataset.map(tokenize_function, batched=True)
tokenized_test = test_dataset.map(tokenize_function, batched=True)

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

!pip install --upgrade transformers

# Install required libraries
!pip install transformers datasets torch --quiet

# Step 1: Load IMDb dataset
from datasets import load_dataset
dataset = load_dataset('imdb')
train_dataset = dataset['train'].shuffle(seed=42).select(range(2000))  # small subset for fast training
test_dataset = dataset['test'].shuffle(seed=42).select(range(1000))

# Step 2: Tokenize using DistilBERT
from transformers import DistilBertTokenizer
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

def tokenize_function(examples):
    return tokenizer(examples['text'], padding="max_length", truncation=True)

tokenized_train = train_dataset.map(tokenize_function, batched=True)
tokenized_test = test_dataset.map(tokenize_function, batched=True)

# Set format for PyTorch
tokenized_train.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])
tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])

# Step 3: Load pre-trained model for classification
from transformers import DistilBertForSequenceClassification
model = DistilBertForSequenceClassification.from_pretrained(
    'distilbert-base-uncased', num_labels=2
)

# Step 4: Define training arguments (minimal for compatibility)
from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=1,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8
)

# Step 5: Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_test
)

# Step 6: Train model
trainer.train()

# Step 7: Evaluate
results = trainer.evaluate()
print(results)

model.save_pretrained("/content/sentiment_model")
tokenizer.save_pretrained("/content/sentiment_model")
!ls /content/sentiment_model

!zip -r sentiment_model.zip /content/sentiment_model

from google.colab import files
files.download("sentiment_model.zip")

from transformers import DistilBertTokenizer, DistilBertForSequenceClassification
import torch

# Load the saved model and tokenizer
model = DistilBertForSequenceClassification.from_pretrained("/content/sentiment_model")
tokenizer = DistilBertTokenizer.from_pretrained("/content/sentiment_model")

# Predict function
def predict_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
        prediction = torch.argmax(probs, dim=-1).item()
        confidence = probs[0][prediction].item()
    return {"prediction": prediction, "confidence": confidence}

# Example predictions
print(predict_sentiment("I absolutely loved this movie!"))
print(predict_sentiment("It was boring and disappointing."))

!pip freeze > requirements.txt

from google.colab import files
files.download("requirements.txt")

!pip install gradio --quiet

import gradio as gr
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification
import torch

# Load model and tokenizer
model = DistilBertForSequenceClassification.from_pretrained("/content/sentiment_model")
tokenizer = DistilBertTokenizer.from_pretrained("/content/sentiment_model")

# Prediction function
def predict(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
        prediction = "Positive" if torch.argmax(probs) == 1 else "Negative"
        confidence = probs[0][torch.argmax(probs)].item()
    return f"{prediction} ({confidence:.2f} confidence)"

# Gradio UI
gr.Interface(fn=predict, inputs="text", outputs="text", title="Sentiment Classifier").launch()